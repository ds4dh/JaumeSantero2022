{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27325ddd-720e-4c13-846e-b5502cc95d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load argument packages\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "# Load transformer package\n",
    "from onmt.translate.translator import Translator\n",
    "from onmt.translate import GNMTGlobalScorer\n",
    "from onmt.model_builder import load_test_model\n",
    "import onmt.opts as opts\n",
    "import onmt\n",
    "\n",
    "# Load data science packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load chemical packages\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Descriptors3D, MolFromSmiles, Lipinski, AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IPythonConsole.molSize = (1000, 300)   # Change image size\n",
    "IPythonConsole.ipython_useSVG = False  # Show as PNG\n",
    "\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# Path to model\n",
    "MODEL_all = '../available_models/MIT_reactants_pred_x10/MIT_reactants_pred_x10_model_average_20.pt'\n",
    "MODEL_one = '../available_models/MIT_1reactant_pred_x10/MIT_1reactant_pred_x10_model_average_20.pt'\n",
    "\n",
    "# Path to data\n",
    "path_src  = '../data/MIT_reactants_pred_x10/src-test.txt'\n",
    "path_tgt  = '../data/MIT_reactants_pred_x10/tgt-test.txt'\n",
    "\n",
    "# Set number of predicted products\n",
    "number_of_products = 3\n",
    "\n",
    "# From SMILES to tokens\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smi)]\n",
    "    assert smi == ''.join(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Get molecule descriptors\n",
    "def get_descriptors_from_mol(mol_obj, descriptors_list, random_seed=0):\n",
    "\n",
    "    descriptors_dict = {k: None for k in descriptors_list}\n",
    "    for k in descriptors_list:\n",
    "        try:\n",
    "            if hasattr(Descriptors, k):\n",
    "                descriptors_dict[k] = getattr(Descriptors, k)(mol_obj)\n",
    "                continue\n",
    "\n",
    "            if hasattr(Descriptors3D, k):\n",
    "                hmol_obj = AllChem.AddHs(mol_obj)\n",
    "                AllChem.EmbedMolecule(hmol_obj, useExpTorsionAnglePrefs=True,\n",
    "                useBasicKnowledge=True, randomSeed=random_seed)\n",
    "                AllChem.UFFOptimizeMolecule(hmol_obj)\n",
    "                descriptors_dict[k] = getattr(Descriptors3D, k)(hmol_obj)\n",
    "                continue\n",
    "\n",
    "            if hasattr(Lipinski, k):\n",
    "                descriptors_dict[k] = getattr(Lipinski, k)(mol_obj)\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        except:\n",
    "                descriptors_dict[k] = None\n",
    "\n",
    "    return descriptors_dict\n",
    "\n",
    "# Reaction prediction function\n",
    "def reactionPrediction(translator, reac_smi):\n",
    "    \n",
    "    \"\"\"    \n",
    "        Input:\n",
    "            Model translator:\n",
    "                translator (object)\n",
    "            Reactants and reagents in SMILES\n",
    "                reac_smi (str)                \n",
    "                Example: reac_smi = 'N#Cc1ccsc1N.O=[N+]([O-])c1cc(F)c(F)cc1F>C1CCOC1.[H-].[Na+]'\n",
    "                \n",
    "        Return:\n",
    "            Scores and products in SMILES:\n",
    "                (list (float32), (list (str))\n",
    "                Example: ([tensor(1.0000)], ['N#Cc1ccsc1Nc1cc(F)c(F)cc1[N+](=O)[O-]'])\n",
    "            \n",
    "        Footnote from Schwaller 2019:\n",
    "            The product of the probabilities of all predicted\n",
    "            tokens are used as a confidence score\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize SMILE molecules\n",
    "    reac_tok = smi_tokenizer(reac_smi)\n",
    "\n",
    "    # Output tokenized product\n",
    "    scores, product_tok = translator.translate_test(src=[reac_tok], batch_size=1)\n",
    "\n",
    "    # Obtain SMILES product from tokenized product\n",
    "    product_smi = [pred.replace(' ','') for pred in product_tok[0]]\n",
    "    \n",
    "    # Transform log-probs into probs\n",
    "    scores = [torch.exp(score) for score in scores[0]]\n",
    "        \n",
    "    return scores, product_smi\n",
    "\n",
    "# Display products and scores in terminal\n",
    "def show_products(scores, products):\n",
    "    print(\"-------------------------\\n\")\n",
    "    print(\"Score\\t\\tProduct\\n\")\n",
    "    print(\"-------------------------\\n\")\n",
    "    for iproduct, product in enumerate(products):\n",
    "        properties = get_descriptors_from_mol(MolFromSmiles(product), descriptors_list, random_seed=0)\n",
    "        print(\"%.2e\\t%s\\n\"%(scores[iproduct], product))\n",
    "        print(properties)\n",
    "        print(\"-------------------------\\n\")\n",
    "        \n",
    "def canonicalize_smi(smi: str, remove_atom_mapping=False) -> str:\n",
    "    \"\"\" Convert a SMILES string into its canonicalized form\n",
    "    Args:\n",
    "        smi: Reaction SMILES\n",
    "        remove_atom_mapping: If True, remove atom mapping information from the canonicalized SMILES output\n",
    "    Returns:\n",
    "        SMILES reaction, canonicalized, as a string\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if not mol:\n",
    "        raise NotCanonicalizableSmilesException(\"Molecule not canonicalizable\")\n",
    "    if remove_atom_mapping:\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.HasProp(\"molAtomMapNumber\"):\n",
    "                atom.ClearProp(\"molAtomMapNumber\")\n",
    "    return Chem.MolToSmiles(mol)\n",
    "\n",
    "class NotCanonicalizableSmilesException(ValueError):\n",
    "    pass\n",
    "        \n",
    "# Loads model translator\n",
    "def load_model(MODEL, number_of_products=1):\n",
    "\n",
    "    # Parsing model parameters\n",
    "    parser = argparse.ArgumentParser(description='translate.py',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    #opts.add_md_help_argument(parser)\n",
    "    opts.translate_opts(parser)\n",
    "    opt = parser.parse_args(['-model=%s'%MODEL,\n",
    "                             '-src=%s'%'CCC',\n",
    "                             '-batch_size=%s'%'64',\n",
    "                             '-replace_unk',\n",
    "                             '-max_length=%s'%'200'])\n",
    "    dummy_parser = argparse.ArgumentParser(description='train.py')\n",
    "    opts.model_opts(dummy_parser)\n",
    "    dummy_opt = dummy_parser.parse_known_args([])[0]\n",
    "\n",
    "    # Load transformer model\n",
    "    fields, model, model_opt = load_test_model(opt)\n",
    "\n",
    "    # Set score parameters\n",
    "    scorer = GNMTGlobalScorer(opt.alpha, opt.beta,\n",
    "                              opt.coverage_penalty,\n",
    "                              opt.length_penalty)\n",
    "\n",
    "    # Create dictionary with model parameters\n",
    "    kwargs = {k: getattr(opt, k)\n",
    "              for k in [\"beam_size\", \"max_length\", \"min_length\",\n",
    "                        \"stepwise_penalty\", \"block_ngram_repeat\",\n",
    "                        \"ignore_when_blocking\", \"dump_beam\",\n",
    "                        \"data_type\", \"replace_unk\"]}\n",
    "\n",
    "    # Create transfomer\n",
    "    translator = Translator(model, fields=fields, global_scorer=scorer,\n",
    "                            report_score=True, out_file=None,\n",
    "                            copy_attn=model_opt.copy_attn, logger=None,\n",
    "                            src_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            tgt_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            n_best=number_of_products, gpu=1, **kwargs)\n",
    "    \n",
    "    return translator\n",
    "\n",
    "# Get descriptors\n",
    "descriptors_list = [\"MolLogP\", \"SlogP_VSA1\", \"Asphericity\", \"TPSA\", \"MolWt\", \"NumHDonors\", \"NumHAcceptors\"]\n",
    "\n",
    "# Generate first predicter\n",
    "first_predicter = load_model(MODEL_all)\n",
    "\n",
    "# Define canonalizer#\n",
    "canonicalize_smi = lambda smi: 'NA' if not Chem.MolFromSmiles(smi) else Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "\n",
    "# Generate second predicter\n",
    "second_predicter = load_model(MODEL_one)\n",
    "\n",
    "# Reactant prediction\n",
    "def reactantsPrediction(reac_smi):\n",
    "\n",
    "    # Canonicalize reaction\n",
    "    reac_smi_canon = '.'.join([canonicalize_smi(n) for n in reac_smi.split('.')])\n",
    "\n",
    "    # Run model for a given reaction\n",
    "    scores, reactants = reactionPrediction(first_predicter, reac_smi_canon)\n",
    "\n",
    "    # Canonicalize reactants and put in a list\n",
    "    reactants_list = [canonicalize_smi(reactant) for reactant in reactants[0].split('.')]\n",
    "\n",
    "    # Use second predicter if one 'NA' is present in first prediction\n",
    "    if reactants_list.count('NA') == 1:\n",
    "        reactants_list.remove('NA')\n",
    "        scores_one, reactant_one = reactionPrediction(second_predicter,  '.'.join(reactants_list) + '.' + reac_smi_canon)\n",
    "        return reactant_one[0] + '.' + '.'.join(reactants_list)\n",
    "    else:\n",
    "        return reactants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50974c5d-64d9-480d-8447-70832467af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "src  = pd.read_csv(path_src, header=None).replace('\\s+', '', regex=True).values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0bb7615-32e7-40e4-a522-e0dc85177544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pred = []\n",
    "N = len(pred)\n",
    "for reaction in src[N:]:\n",
    "    pred.append(reactantsPrediction(reaction)[0])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9be49d29-9208-4af7-93ec-80b436ca62e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy (all reactants) = 70.59 %\n",
      "Top-1 accuracy (at least 1)    = 82.28 %\n"
     ]
    }
   ],
   "source": [
    "# Load target\n",
    "tgt  = pd.read_csv(path_tgt, header=None).replace('\\s+', '', regex=True).values.flatten().tolist()\n",
    "\n",
    "# Calulate top-1 accuracy\n",
    "counter_all = 0\n",
    "counter_one = 0\n",
    "for i in range(len(pred)):\n",
    "    tgt_list = sorted([canonicalize_smi(j) for j in tgt[i].split('.')])\n",
    "    pred_list = sorted([canonicalize_smi(j) for j in pred[i].split('.')])\n",
    "    if tgt_list == pred_list:\n",
    "        counter_all += 1\n",
    "    for j in pred_list:\n",
    "        if j in tgt_list and j != 'NA':\n",
    "            counter_one += 1\n",
    "            break\n",
    "print('Top-1 accuracy (all reactants) = %.2f %%'%(100 * counter_all / len(pred)))\n",
    "print('Top-1 accuracy (at least 1)    = %.2f %%'%(100 * counter_one / len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8be8239b-d9ca-4604-8570-d759525e1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../results/predictions_MIT_enhanced_reactants_pred_model_on_MIT_reactants_pred_test_V2.txt'\n",
    "with open(save_path, 'w') as f:\n",
    "    for item in pred:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
