{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa793457-406c-401a-8ebf-638305595da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data science packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load argument packages\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "# Load transformer package\n",
    "import onmt\n",
    "import onmt.opts as opts\n",
    "from onmt.translate import GNMTGlobalScorer\n",
    "from onmt.model_builder import load_test_model\n",
    "from onmt.translate.translator import Translator\n",
    "\n",
    "# Load chemistry packages\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit import RDLogger \n",
    "import rdkit.Chem.AllChem as AllChem\n",
    "from rdkit.Chem import Descriptors, Descriptors3D, MolFromSmiles, Lipinski, AllChem                                                                                                                                                            \n",
    "\n",
    "# Non-verbose rdkit\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# SMILES functions\n",
    "canonicalize_smi = lambda smi: 'NA' if not Chem.MolFromSmiles(smi) else Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "equivalent_smi   = lambda smi: 'NA' if not Chem.MolFromSmiles(smi) else Chem.MolToSmiles(Chem.MolFromSmiles(smi), doRandom=True)\n",
    "\n",
    "# Get molecule descriptors\n",
    "def get_descriptors_from_mol(mol_obj, descriptors_list, random_seed=0):\n",
    "\n",
    "    descriptors_dict = {k: None for k in descriptors_list}\n",
    "    for k in descriptors_list:\n",
    "        try:\n",
    "            if hasattr(Descriptors, k):\n",
    "                descriptors_dict[k] = getattr(Descriptors, k)(mol_obj)\n",
    "                continue\n",
    "\n",
    "            if hasattr(Descriptors3D, k):\n",
    "                hmol_obj = AllChem.AddHs(mol_obj)\n",
    "                AllChem.EmbedMolecule(hmol_obj, useExpTorsionAnglePrefs=True,\n",
    "                useBasicKnowledge=True, randomSeed=random_seed)\n",
    "                AllChem.UFFOptimizeMolecule(hmol_obj)\n",
    "                descriptors_dict[k] = getattr(Descriptors3D, k)(hmol_obj)\n",
    "                continue\n",
    "\n",
    "            if hasattr(Lipinski, k):\n",
    "                descriptors_dict[k] = getattr(Lipinski, k)(mol_obj)\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        except:\n",
    "                descriptors_dict[k] = None\n",
    "\n",
    "    return descriptors_dict\n",
    "\n",
    "# From SMILES to tokens\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smi)]\n",
    "    assert smi == ''.join(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Product prediction function\n",
    "def productPrediction(translator, reac_smi):\n",
    "\n",
    "    # Tokenize SMILE molecules\n",
    "    reac_tok = smi_tokenizer(reac_smi)\n",
    "\n",
    "    # Output tokenized product\n",
    "    scores, product_tok = translator.translate_test(src=[reac_tok], batch_size=1)\n",
    "\n",
    "    # Obtain SMILES product from tokenized product\n",
    "    product_smi = [pred.replace(' ','') for pred in product_tok[0]]\n",
    "    \n",
    "    # Transform log-probs into probs\n",
    "    scores = [torch.exp(score) for score in scores[0]]\n",
    "        \n",
    "    return scores, product_smi\n",
    "\n",
    "# Reactants prediction function\n",
    "def reactantsPrediction(translator, reac_smi):\n",
    "\n",
    "    # Tokenize SMILE molecules\n",
    "    reac_tok = smi_tokenizer(reac_smi)\n",
    "\n",
    "    # Output tokenized product\n",
    "    scores, reactants_tok = translator.translate_test(src=[reac_tok], batch_size=1)\n",
    "\n",
    "    # Obtain SMILES product from tokenized product\n",
    "    reactants_smi = [pred.replace(' ','') for pred in reactants_tok[0]]\n",
    "    \n",
    "    # Transform log-probs into probs\n",
    "    scores = [torch.exp(score) for score in scores[0]]\n",
    "        \n",
    "    return scores, reactants_smi\n",
    "\n",
    "# Loads model translator\n",
    "def load_model(MODEL, number_of_solutions=1):\n",
    "\n",
    "    # Parsing model parameters\n",
    "    parser = argparse.ArgumentParser(description='translate.py',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    opts.translate_opts(parser)\n",
    "    opt = parser.parse_args(['-model=%s'%MODEL,\n",
    "                             '-src=%s'%'CCC',\n",
    "                             '-batch_size=%s'%'64',\n",
    "                             '-replace_unk',\n",
    "                             '-max_length=%s'%'200'])\n",
    "    dummy_parser = argparse.ArgumentParser(description='train.py')\n",
    "    opts.model_opts(dummy_parser)\n",
    "    dummy_opt = dummy_parser.parse_known_args([])[0]\n",
    "\n",
    "    # Load transformer model\n",
    "    fields, model, model_opt = load_test_model(opt)\n",
    "\n",
    "    # Set score parameters\n",
    "    scorer = GNMTGlobalScorer(opt.alpha, opt.beta,\n",
    "                              opt.coverage_penalty,\n",
    "                              opt.length_penalty)\n",
    "\n",
    "    # Create dictionary with model parameters\n",
    "    kwargs = {k: getattr(opt, k)\n",
    "              for k in [\"beam_size\", \"max_length\", \"min_length\",\n",
    "                        \"stepwise_penalty\", \"block_ngram_repeat\",\n",
    "                        \"ignore_when_blocking\", \"dump_beam\",\n",
    "                        \"data_type\", \"replace_unk\"]}\n",
    "\n",
    "    # Create transfomer\n",
    "    translator = Translator(model, fields=fields, global_scorer=scorer,\n",
    "                            report_score=True, out_file=None,\n",
    "                            copy_attn=model_opt.copy_attn, logger=None,\n",
    "                            src_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            tgt_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            n_best=number_of_products, gpu=-1, **kwargs)\n",
    "    \n",
    "    return translator\n",
    "\n",
    "# Get descriptors\n",
    "descriptors_list = [\"MolLogP\", \"SlogP_VSA1\", \"Asphericity\", \"TPSA\", \"MolWt\", \"NumHDonors\", \"NumHAcceptors\"]\n",
    "\n",
    "# Paths to models\n",
    "MODEL_product   = '../available_models/MIT_mixed_augm/MIT_mixed_augm_model_average_20.pt'\n",
    "MODEL_reactants = '../available_models/MIT_reactants_pred_x10/MIT_reactants_pred_x10_model_average_20.pt'\n",
    "\n",
    "# Set number of predicted products\n",
    "number_of_products  = 1\n",
    "number_of_reactants = 1\n",
    "\n",
    "# Generate translators for product and reactants prediction\n",
    "translator_product   = load_model(MODEL_product, number_of_products)\n",
    "translator_reactants = load_model(MODEL_reactants, number_of_reactants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da06056d-2f5b-41d4-90a1-4005cd4655a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product prediction examples\n",
    "smi_prod_pred = 'O=C(CCCN1CCC(NS(=O)(=O)c2ccccc2)CC1)c1ccccc1.[BH4-].[Na+]'\n",
    "# smi_prod_pred = 'N#Cc1ccsc1N.O=[N+]([O-])c1cc(F)c(F)cc1F.C1CCOC1.[H-].[Na+]'\n",
    "# smi_prod_pred = 'BrCC(C1)(C(C2=CC=CO2)O)CN1S(C3=CC=C(C)C=C3)(=O)=O.CO.O=C(O[K])O[K]'\n",
    "\n",
    "# Reactants prediction examples\n",
    "smi_reac_pred = 'N#Cc1ccsc1Nc1cc(F)c(F)cc1[N+](=O)[O-]'\n",
    "\n",
    "# OPTIONAL: canonicalize molecules\n",
    "smi_prod_pred_canon = '.'.join([canonicalize_smi(n) for n in smi_prod_pred.split('.')])\n",
    "smi_reac_pred_canon = '.'.join([canonicalize_smi(n) for n in smi_reac_pred.split('.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc022f3c-674b-4ba5-9ad4-d503e16b2e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.0000)] ['O=S(=O)(NC1CCN(CCCC(O)c2ccccc2)CC1)c1ccccc1']\n",
      "[tensor(0.9996)] ['N#Cc1ccsc1N.O=[N+]([O-])c1cc(F)c(F)cc1F']\n"
     ]
    }
   ],
   "source": [
    "# Run model for product prediction\n",
    "scores_prod, products = productPrediction(translator_product, smi_prod_pred_canon)\n",
    "\n",
    "# Run model for product prediction\n",
    "scores_reac, reactants = reactantsPrediction(translator_reactants, smi_reac_pred_canon)\n",
    "\n",
    "print(scores_prod, products)\n",
    "print(scores_reac, reactants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d01afd-0ce9-4968-b17e-c15bb7c21532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MolLogP': 2.943100000000001, 'SlogP_VSA1': 4.722094864452088, 'Asphericity': 0.6456066481054452, 'TPSA': 69.64, 'MolWt': 388.53300000000013, 'NumHDonors': 2, 'NumHAcceptors': 4}\n",
      "{'MolLogP': 1.20198, 'SlogP_VSA1': 5.733667477162185, 'Asphericity': 0.35651882271080215, 'TPSA': 49.81, 'MolWt': 124.16799999999999, 'NumHDonors': 1, 'NumHAcceptors': 3}\n",
      "{'MolLogP': 2.0120999999999998, 'SlogP_VSA1': 0.0, 'Asphericity': 0.38490968186421487, 'TPSA': 43.14, 'MolWt': 177.081, 'NumHDonors': 0, 'NumHAcceptors': 2}\n"
     ]
    }
   ],
   "source": [
    "# Show product descriptors\n",
    "print(get_descriptors_from_mol(MolFromSmiles(products[0]), descriptors_list, random_seed=0))\n",
    "\n",
    "# Show descriptors for each reactant\n",
    "for reactant in reactants[0].split('.'):\n",
    "    print(get_descriptors_from_mol(MolFromSmiles(reactant), descriptors_list, random_seed=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
