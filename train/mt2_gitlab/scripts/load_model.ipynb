{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27325ddd-720e-4c13-846e-b5502cc95d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load argument packages\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "# Load transformer package\n",
    "from onmt.translate.translator import Translator\n",
    "from onmt.translate import GNMTGlobalScorer\n",
    "from onmt.model_builder import load_test_model\n",
    "import onmt.opts as opts\n",
    "import onmt\n",
    "\n",
    "# Load data science packages\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load chemical packages\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Descriptors3D, MolFromSmiles, Lipinski, AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IPythonConsole.molSize = (1000, 300)   # Change image size\n",
    "IPythonConsole.ipython_useSVG = False  # Show as PNG\n",
    "\n",
    "# Path to model\n",
    "MODEL_prod_pred = '../available_models/MIT_mixed_augm/MIT_mixed_augm_model_average_20.pt'\n",
    "MODEL_react_pred = '../available_models/MIT_product_pred_x10/MIT_product_pred_x10_model_average_20.pt'\n",
    "\n",
    "# Set number of predicted products\n",
    "number_of_products = 3\n",
    "\n",
    "# From SMILES to tokens\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smi)]\n",
    "    assert smi == ''.join(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Get molecule descriptors\n",
    "def get_descriptors_from_mol(mol_obj, descriptors_list, random_seed=0):\n",
    "\n",
    "    descriptors_dict = {k: None for k in descriptors_list}\n",
    "    for k in descriptors_list:\n",
    "        try:\n",
    "            if hasattr(Descriptors, k):\n",
    "                descriptors_dict[k] = getattr(Descriptors, k)(mol_obj)\n",
    "                continue\n",
    "\n",
    "            if hasattr(Descriptors3D, k):\n",
    "                hmol_obj = AllChem.AddHs(mol_obj)\n",
    "                AllChem.EmbedMolecule(hmol_obj, useExpTorsionAnglePrefs=True,\n",
    "                useBasicKnowledge=True, randomSeed=random_seed)\n",
    "                AllChem.UFFOptimizeMolecule(hmol_obj)\n",
    "                descriptors_dict[k] = getattr(Descriptors3D, k)(hmol_obj)\n",
    "                continue\n",
    "\n",
    "            if hasattr(Lipinski, k):\n",
    "                descriptors_dict[k] = getattr(Lipinski, k)(mol_obj)\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        except:\n",
    "                descriptors_dict[k] = None\n",
    "\n",
    "    return descriptors_dict\n",
    "\n",
    "# Reaction prediction function\n",
    "def reactionPrediction(translator, reac_smi):\n",
    "    \n",
    "    \"\"\"    \n",
    "        Input:\n",
    "            Model translator:\n",
    "                translator (object)\n",
    "            Reactants and reagents in SMILES\n",
    "                reac_smi (str)                \n",
    "                Example: reac_smi = 'N#Cc1ccsc1N.O=[N+]([O-])c1cc(F)c(F)cc1F>C1CCOC1.[H-].[Na+]'\n",
    "                \n",
    "        Return:\n",
    "            Scores and products in SMILES:\n",
    "                (list (float32), (list (str))\n",
    "                Example: ([tensor(1.0000)], ['N#Cc1ccsc1Nc1cc(F)c(F)cc1[N+](=O)[O-]'])\n",
    "            \n",
    "        Footnote from Schwaller 2019:\n",
    "            The product of the probabilities of all predicted\n",
    "            tokens are used as a confidence score\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize SMILE molecules\n",
    "    reac_tok = smi_tokenizer(reac_smi)\n",
    "\n",
    "    # Output tokenized product\n",
    "    scores, product_tok = translator.translate_test(src=[reac_tok], batch_size=1)\n",
    "\n",
    "    # Obtain SMILES product from tokenized product\n",
    "    product_smi = [pred.replace(' ','') for pred in product_tok[0]]\n",
    "    \n",
    "    # Transform log-probs into probs\n",
    "    scores = [torch.exp(score) for score in scores[0]]\n",
    "        \n",
    "    return scores, product_smi\n",
    "\n",
    "# Display products and scores in terminal\n",
    "def show_products(scores, products):\n",
    "    print(\"-------------------------\\n\")\n",
    "    print(\"Score\\t\\tProduct\\n\")\n",
    "    print(\"-------------------------\\n\")\n",
    "    for iproduct, product in enumerate(products):\n",
    "        properties = get_descriptors_from_mol(MolFromSmiles(product), descriptors_list, random_seed=0)\n",
    "        print(\"%.2e\\t%s\\n\"%(scores[iproduct], product))\n",
    "        print(properties)\n",
    "        print(\"-------------------------\\n\")\n",
    "        \n",
    "def canonicalize_smi(smi: str, remove_atom_mapping=False) -> str:\n",
    "    \"\"\" Convert a SMILES string into its canonicalized form\n",
    "    Args:\n",
    "        smi: Reaction SMILES\n",
    "        remove_atom_mapping: If True, remove atom mapping information from the canonicalized SMILES output\n",
    "    Returns:\n",
    "        SMILES reaction, canonicalized, as a string\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if not mol:\n",
    "        raise NotCanonicalizableSmilesException(\"Molecule not canonicalizable\")\n",
    "    if remove_atom_mapping:\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.HasProp(\"molAtomMapNumber\"):\n",
    "                atom.ClearProp(\"molAtomMapNumber\")\n",
    "    return Chem.MolToSmiles(mol)\n",
    "\n",
    "class NotCanonicalizableSmilesException(ValueError):\n",
    "    pass\n",
    "        \n",
    "# Loads model translator\n",
    "def load_model(number_of_products=1):\n",
    "\n",
    "    # Parsing model parameters\n",
    "    parser = argparse.ArgumentParser(description='translate.py',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    #opts.add_md_help_argument(parser)\n",
    "    opts.translate_opts(parser)\n",
    "    opt = parser.parse_args(['-model=%s'%MODEL,\n",
    "                             '-src=%s'%'CCC',\n",
    "                             '-batch_size=%s'%'64',\n",
    "                             '-replace_unk',\n",
    "                             '-max_length=%s'%'200'])\n",
    "    dummy_parser = argparse.ArgumentParser(description='train.py')\n",
    "    opts.model_opts(dummy_parser)\n",
    "    dummy_opt = dummy_parser.parse_known_args([])[0]\n",
    "\n",
    "    # Load transformer model\n",
    "    fields, model, model_opt = load_test_model(opt)\n",
    "\n",
    "    # Set score parameters\n",
    "    scorer = GNMTGlobalScorer(opt.alpha, opt.beta,\n",
    "                              opt.coverage_penalty,\n",
    "                              opt.length_penalty)\n",
    "\n",
    "    # Create dictionary with model parameters\n",
    "    kwargs = {k: getattr(opt, k)\n",
    "              for k in [\"beam_size\", \"max_length\", \"min_length\",\n",
    "                        \"stepwise_penalty\", \"block_ngram_repeat\",\n",
    "                        \"ignore_when_blocking\", \"dump_beam\",\n",
    "                        \"data_type\", \"replace_unk\"]}\n",
    "\n",
    "    # Create transfomer\n",
    "    translator = Translator(model, fields=fields, global_scorer=scorer,\n",
    "                            report_score=True, out_file=None,\n",
    "                            copy_attn=model_opt.copy_attn, logger=None,\n",
    "                            src_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            tgt_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            n_best=number_of_products, gpu=-1, **kwargs)\n",
    "    \n",
    "    return translator\n",
    "\n",
    "# Get descriptors\n",
    "descriptors_list = [\"MolLogP\", \"SlogP_VSA1\", \"Asphericity\", \"TPSA\", \"MolWt\", \"NumHDonors\", \"NumHAcceptors\"]\n",
    "\n",
    "# Generate translator\n",
    "translator_product = load_model(number_of_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6d36741-dd48-4f42-8c7b-128671df1bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:26:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:26:44] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "\n",
      "Score\t\tProduct\n",
      "\n",
      "-------------------------\n",
      "\n",
      "1.00e+00\tN#Cc1ccsc1Nc1cc(F)c(F)cc1[N+](=O)[O-]\n",
      "\n",
      "{'MolLogP': 3.549780000000001, 'SlogP_VSA1': 5.316788604006331, 'Asphericity': 0.2897604794989785, 'TPSA': 78.96, 'MolWt': 281.243, 'NumHDonors': 1, 'NumHAcceptors': 5}\n",
      "-------------------------\n",
      "\n",
      "6.66e-07\tN#Cc1ccsc1Nc1c(F)cc(F)cc1[N+](=O)[O-]\n",
      "\n",
      "{'MolLogP': 3.549780000000001, 'SlogP_VSA1': 5.316788604006331, 'Asphericity': 0.2779745916728286, 'TPSA': 78.96, 'MolWt': 281.243, 'NumHDonors': 1, 'NumHAcceptors': 5}\n",
      "-------------------------\n",
      "\n",
      "4.02e-07\tN#Cc1ccsc1Nc1nc(F)c(F)cc1[N+](=O)[O-]\n",
      "\n",
      "{'MolLogP': 2.9447800000000006, 'SlogP_VSA1': 5.316788604006331, 'Asphericity': 0.29568751092400264, 'TPSA': 91.85, 'MolWt': 282.231, 'NumHDonors': 1, 'NumHAcceptors': 6}\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write SMILES reaction\n",
    "\n",
    "# 100 %\n",
    "# reac_smi = 'O=C(CCCN1CCC(NS(=O)(=O)c2ccccc2)CC1)c1ccccc1.[BH4-].[Na+]'\n",
    "# tgt = 'O=S(=O)(NC1CCN(CCCC(O)c2ccccc2)CC1)c1ccccc1'\n",
    "\n",
    "# top-1 50 % & top-2 10 %\n",
    "# reac_smi = 'BrCC(C1)(C(C2=CC=CO2)O)CN1S(C3=CC=C(C)C=C3)(=O)=O.CO.O=C(O[K])O[K]'\n",
    "# tgt = 'CC4=CC=C(S(N5CC6(COC6C7=CC=CO7)C5)(=O)=O)C=C4'\n",
    "\n",
    "# 100 %\n",
    "reac_smi = 'N#Cc1ccsc1N.O=[N+]([O-])c1cc(F)c(F)cc1F.C1CCOC1.[H-].[Na+]'\n",
    "tgt = 'N#Cc1ccsc1Nc1cc(F)c(F)cc1[N+](=O)[O-]'\n",
    "\n",
    "reac_smi_canon = '.'.join([canonicalize_smi(n) for n in reac_smi.split('.')])\n",
    "\n",
    "# Run model for a given reaction\n",
    "scores, products = reactionPrediction(translator, reac_smi_canon)\n",
    "\n",
    "# Show results in terminal\n",
    "show_products(scores, products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4dbe977-4774-4c5f-b4a5-192557e05a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canonicalize_smi(products[0]) == canonicalize_smi(tgt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
