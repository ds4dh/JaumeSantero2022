{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d90dbabc-5420-4ab1-8631-edbfa3130f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data science packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load argument packages\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "# Load chemistry packages\n",
    "import rdkit.Chem as Chem\n",
    "import rdkit.Chem.AllChem as AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole \n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import RDLogger                                                                                                                                                               \n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "PandasTools.RenderImagesInAllDataFrames(images=True)\n",
    "\n",
    "# Load visualization package and display settings\n",
    "import matplotlib.pyplot as plt\n",
    "IPythonConsole.molSize = (1000, 300)   # Change image size\n",
    "IPythonConsole.ipython_useSVG = False  # Show as PNG\n",
    "\n",
    "#path_src  = '../data/MIT_reactants_pred_8M_noreagents/src-test.txt'\n",
    "#path_tgt  = '../data/MIT_reactants_pred_8M_noreagents/tgt-test.txt'\n",
    "#path_pred = '../results/predictions_MIT_reactants_pred_8M_noreagents_model_average_20_on_MIT_reactants_pred_8M_noreagents_test.txt'\n",
    "\n",
    "path_src  = '../data/round_trip/src-rt-800k.txt'\n",
    "path_tgt  = '../data/round_trip/tgt-rt-800k.txt'\n",
    "path_pred = '../results/round_trip/predictions_rt_800k.txt'\n",
    "\n",
    "# Load data\n",
    "src  = pd.read_csv(path_src, header=None).replace('\\s+', '', regex=True).values.flatten().tolist()\n",
    "pred = pd.read_csv(path_pred, header=None).replace('\\s+', '', regex=True).values.flatten().tolist()\n",
    "tgt  = pd.read_csv(path_tgt, header=None).replace('\\s+', '', regex=True).values.flatten().tolist()\n",
    "\n",
    "# SMILES functions\n",
    "canonicalize_smi = lambda smi: 'NA' if not Chem.MolFromSmiles(smi) else Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "equivalent_smi   = lambda smi: 'NA' if not Chem.MolFromSmiles(smi) else Chem.MolToSmiles(Chem.MolFromSmiles(smi), doRandom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a09c3c68-44fc-4781-82f7-e17bc183363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy (all reactants) = 90.49 %\n",
      "Top-1 accuracy (at least 1)    = 90.72 %\n"
     ]
    }
   ],
   "source": [
    "counter_all = 0\n",
    "counter_one = 0\n",
    "for i in range(len(tgt)):\n",
    "    tgt_list = sorted([canonicalize_smi(j) for j in tgt[i].split('.')])\n",
    "    pred_list = sorted([canonicalize_smi(j) for j in pred[i].split('.')])\n",
    "    if tgt_list == pred_list:\n",
    "        counter_all += 1\n",
    "    for j in pred_list:\n",
    "        if j in tgt_list and j != 'NA':\n",
    "            counter_one += 1\n",
    "            break\n",
    "print('Top-1 accuracy (all reactants) = %.2f %%'%(100 * counter_all / len(tgt)))\n",
    "print('Top-1 accuracy (at least 1)    = %.2f %%'%(100 * counter_one / len(tgt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "184aa451-73e4-40ab-976e-48b93aa56449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src, tgt, pred, error\n",
    "error_reactants  = []\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    tgt_list = sorted([canonicalize_smi(j) for j in tgt[i].split('.')])\n",
    "    pred_list = sorted([canonicalize_smi(j) for j in pred[i].split('.')])\n",
    "    if 'NA' in pred_list:\n",
    "        continue\n",
    "    if 'NA' in tgt_list:\n",
    "        print('Error in target: %s'%(tgt[i]))\n",
    "        continue\n",
    "    if tgt_list != pred_list:\n",
    "        error_reactants.append(','.join([src[i], tgt[i], pred[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f627974-285f-43ca-bc0e-fdae53456a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_trip = []\n",
    "for i, s in enumerate(error_reactants):\n",
    "    \n",
    "    reactants = s.split(',')[-1]\n",
    "    product   = s.split(',')[0].split('.')[-1]\n",
    "    reagents  = '.'.join([n for n in s.split(',')[0].split('.') if n != product])\n",
    "    round_trip.append([reactants + '.' + reagents, reactants, product])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44e15267-1bc9-472d-ba31-c829c430d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SMILES to tokens\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smi)]\n",
    "    assert smi == ''.join(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "56462a13-6b1e-438d-bd4d-d4c6f537edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load argument packages\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "# Load transformer package\n",
    "from onmt.translate.translator import Translator\n",
    "from onmt.translate import GNMTGlobalScorer\n",
    "from onmt.model_builder import load_test_model\n",
    "import onmt.opts as opts\n",
    "import onmt\n",
    "\n",
    "# Load data science packages\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load chemical packages\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Descriptors3D, MolFromSmiles, Lipinski, AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IPythonConsole.molSize = (1000, 300)   # Change image size\n",
    "IPythonConsole.ipython_useSVG = False  # Show as PNG\n",
    "\n",
    "# Path to model\n",
    "MODEL = '../available_models/MIT_mixed_augm/MIT_mixed_augm_model_average_20.pt'\n",
    "\n",
    "# Set number of predicted products\n",
    "number_of_products = 1\n",
    "\n",
    "# Reaction prediction function\n",
    "def reactionPrediction(translator, reac_smi):\n",
    "\n",
    "    # Tokenize SMILE molecules\n",
    "    reac_tok = smi_tokenizer(reac_smi)\n",
    "\n",
    "    # Output tokenized product\n",
    "    scores, product_tok = translator.translate_test(src=[reac_tok], batch_size=1)\n",
    "\n",
    "    # Obtain SMILES product from tokenized product\n",
    "    product_smi = [pred.replace(' ','') for pred in product_tok[0]]\n",
    "    \n",
    "    # Transform log-probs into probs\n",
    "    scores = [torch.exp(score) for score in scores[0]]\n",
    "        \n",
    "    return scores, product_smi\n",
    "        \n",
    "# Loads model translator\n",
    "def load_model(number_of_products=1):\n",
    "\n",
    "    # Parsing model parameters\n",
    "    parser = argparse.ArgumentParser(description='translate.py',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    #opts.add_md_help_argument(parser)\n",
    "    opts.translate_opts(parser)\n",
    "    opt = parser.parse_args(['-model=%s'%MODEL,\n",
    "                             '-src=%s'%'CCC',\n",
    "                             '-batch_size=%s'%'64',\n",
    "                             '-replace_unk',\n",
    "                             '-max_length=%s'%'200'])\n",
    "    dummy_parser = argparse.ArgumentParser(description='train.py')\n",
    "    opts.model_opts(dummy_parser)\n",
    "    dummy_opt = dummy_parser.parse_known_args([])[0]\n",
    "\n",
    "    # Load transformer model\n",
    "    fields, model, model_opt = load_test_model(opt)\n",
    "\n",
    "    # Set score parameters\n",
    "    scorer = GNMTGlobalScorer(opt.alpha, opt.beta,\n",
    "                              opt.coverage_penalty,\n",
    "                              opt.length_penalty)\n",
    "\n",
    "    # Create dictionary with model parameters\n",
    "    kwargs = {k: getattr(opt, k)\n",
    "              for k in [\"beam_size\", \"max_length\", \"min_length\",\n",
    "                        \"stepwise_penalty\", \"block_ngram_repeat\",\n",
    "                        \"ignore_when_blocking\", \"dump_beam\",\n",
    "                        \"data_type\", \"replace_unk\"]}\n",
    "\n",
    "    # Create transfomer\n",
    "    translator = Translator(model, fields=fields, global_scorer=scorer,\n",
    "                            report_score=True, out_file=None,\n",
    "                            copy_attn=model_opt.copy_attn, logger=None,\n",
    "                            src_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            tgt_reader=onmt.inputters.str2reader[\"text\"],\n",
    "                            n_best=number_of_products, gpu=-1, **kwargs)\n",
    "    \n",
    "    return translator\n",
    "\n",
    "# Generate translator\n",
    "translator = load_model(number_of_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "435a83a8-3240-4947-954e-e1d992c071c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 11379]\n",
      "[1001 / 11379]\n",
      "[2001 / 11379]\n",
      "[3001 / 11379]\n",
      "[4001 / 11379]\n",
      "[5001 / 11379]\n",
      "[6001 / 11379]\n",
      "[7001 / 11379]\n",
      "[8001 / 11379]\n",
      "[9001 / 11379]\n",
      "[10001 / 11379]\n",
      "[11001 / 11379]\n",
      "CPU times: user 1d 22h 58min 27s, sys: 1min 59s, total: 1d 23h 26s\n",
      "Wall time: 54min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pass_fail = []\n",
    "for i,reaction in enumerate(round_trip):\n",
    "    scores, products = reactionPrediction(translator, reaction[0])\n",
    "    if products[0] == reaction[-1]:\n",
    "        pass_fail.append('PASS')\n",
    "    else:\n",
    "        pass_fail.append('FAIL')\n",
    "    if i%1000 == 0:\n",
    "        print('[%d / %d]'%(i+1, len(round_trip)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "771c8693-f951-438d-abd8-2cf1c3090645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 72.78 %\n",
      "Fail: 27.22 %\n"
     ]
    }
   ],
   "source": [
    "print('Pass: %.2f %%'%(100 * pass_fail.count('PASS') / len(pass_fail)))\n",
    "print('Fail: %.2f %%'%(100 * pass_fail.count('FAIL') / len(pass_fail)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7fc2ddcb-78e0-4382-93ac-31f3e44a1abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round trip pass = 92.05 %\n"
     ]
    }
   ],
   "source": [
    "print('Round trip pass = %.2f %%'%(100 * (len(pred) - len(error_reactants) + pass_fail.count('PASS')) / len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bf9c1506-c5c8-4d1c-a13e-15d5b26d1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../results/wrong_reactant_predictions_V2.csv'\n",
    "with open(save_path, 'w+') as f:\n",
    "    f.write(\"src,tgt,pred,round_trip\\n\" )\n",
    "    for it, item in enumerate(error_reactants):\n",
    "        f.write(\"%s\\n\" % (item + ',' + pass_fail[it]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
